{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "from string import Template\n",
    "from csv import QUOTE_ALL \n",
    "import time\n",
    "import os \n",
    "\n",
    "import teradata\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import requests.auth\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Standard Metrics API Caller. Provides the following metrics: \n",
    "      \"traffic_in\",\n",
    "      \"traffic_out\",\n",
    "      \"dwell_count\",\n",
    "      \"avg_dwell_duration\",\n",
    "      \"engagement_rate\"\n",
    "\n",
    "Outputs: results_<startdate>_<enddate>.csv\n",
    "\n",
    "To use the RetailNext API, please refer to http://docs.retailnext.net/cloud/api/ for information. \n",
    "\n",
    "Step 1: Create Tokens at https://<subscription>.cloud.retailnext.net/admin/system-api-tokens\n",
    "Step 2: Input Tokens into the file below\n",
    "Step 3: Change the start date and end date below\n",
    "Step 4: Press shift enter to run\n",
    "\n",
    "If you would like to change any of the queries, please use change the post_request variable below.\n",
    "\n",
    "Implementation Notes:\n",
    "\n",
    "There were two approaches I could have done for locations. First approach was to iterate through each \n",
    "location for eaach query.\n",
    "The second approach was to embed all locations inside the initial request file. \n",
    "I chose approach 1. \n",
    "\n",
    "\n",
    "Work to do: \n",
    "Better Pagination handling. \n",
    "More Error Handling  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" PLACE YOUR ACCESS CODES HERE \"\"\"\n",
    "ACCESS_CODE = \"********\"\n",
    "SECRET_KEY =  \"********\"\n",
    "CUSTOMER = \"*****\"\n",
    "GET_URL = \"https://\" + CUSTOMER + \".api.retailnext.net/v1/location\"\n",
    "POST_URL = \"https://\" + CUSTOMER + \".api.retailnext.net/v1/datamine\"\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "conn=pyodbc.connect('DRIVER={Teradata Database ODBC Driver 16.20};DBCNAME=*****;UID=*****;PWD=*****;QUIETMODE=YES;')\n",
    "\n",
    "max_date_plus_one = pd.read_sql(\"select max(txn_strt_dt)+1  from ABFRL_VRDM.SLS_TXN_LINE\", con=conn)\n",
    "max_date_plus_one=str(max_date_plus_one.iloc[0,0])\n",
    "\n",
    "START_DATE = '2017-09-01'\n",
    "#START_DATE=max_date\n",
    "STOP_DATE=str(pd.to_datetime('today'))[:10]\n",
    "\n",
    "OUT_FILE = \"./AEO_Traffic_\" + START_DATE + \"_\" + STOP_DATE + \".csv\"\n",
    "f = open(OUT_FILE, 'w')\n",
    "f.close()\n",
    "\n",
    "\"\"\" Get all the locations and print them \"\"\"\n",
    "def get_locations():\n",
    "\n",
    "    # Initial Call\n",
    "    request = requests.get(GET_URL, auth=(ACCESS_CODE, SECRET_KEY))\n",
    "    request.encoding = 'ISO-8859-1'\n",
    "    j = request.json()\n",
    "   \n",
    "    for location in j['locations']:\n",
    "        get_metrics(location) #Pass the location off to the call for metadata later. \n",
    "\n",
    "    #Handle Pagination \n",
    "    while(isNextPage(request)): #Partial \n",
    "          print('Working on Next Page', request.headers['X-Page-Next'])\n",
    "          headers = {'X-Page-Start': request.headers['X-Page-Next']}\n",
    "          request = requests.get(GET_URL, auth=(ACCESS_CODE, SECRET_KEY), headers=headers)\n",
    "          j = request.json()\n",
    "\n",
    "          for location in j['locations']:\n",
    "             get_metrics(location) #Pass the location off to the call for metadata later.\n",
    "\n",
    "\n",
    "\"\"\"Check if status code is 206. If 206, then pagination is occuring. Need to iterate.\"\"\"\n",
    "def isNextPage(request):\n",
    "    if(request.status_code == 206):\n",
    "      return True\n",
    "    return False\n",
    "\n",
    "\"\"\" TODO: Generic Function to support Pagination Requests. Takes a input call and adds headers to it. \"\"\"\n",
    "def getNextPage(request):\n",
    "    headers = {'X-Page-Start': request.headers['X-Page-Next']}\n",
    "\n",
    "\n",
    "\"\"\" Get all available metrics. Test the post call. \"\"\"\n",
    "def get_metrics(location):\n",
    "    location_id = location['id']\n",
    "    if location['type'] == \"store\":\n",
    "      print(\"Getting Metrics for location:  \", location_id)\n",
    "      post_request[\"locations\"][0] = location_id\n",
    "      payload = json.dumps(post_request, ensure_ascii=False)\n",
    "      post = requests.post(POST_URL, auth=(ACCESS_CODE, SECRET_KEY), data = payload , headers={'content-type': 'application/json'}\n",
    "  )\n",
    "      try: #in case the data that comes back can't be converted to json. \n",
    "        j = post.json()\n",
    "        writeToCSV(j, location)\n",
    "      except ValueError:\n",
    "        print('JSON value failed to return for this location')\n",
    "\n",
    "      while(isNextPage(post)): #Partial \n",
    "          print(\"Getting Metrics for location:  \", location_id)\n",
    "          headers = {'content-type': 'application/json', 'X-Page-Start': request.headers['X-Page-Next']}\n",
    "          payload = json.dumps(post_request, ensure_ascii=False)\n",
    "          post = requests.post(POST_URL, auth=(ACCESS_CODE, SECRET_KEY), data = payload , headers=headers)\n",
    "          try:\n",
    "              j = post.json()\n",
    "              writeToCSV(j, location)\n",
    "          except ValueError:\n",
    "              print('JSON value failed to return for this location')\n",
    "      \n",
    "   \n",
    "\"\"\"\n",
    "   Right now this is an hourly pull from the data, \n",
    "   assuming structured data form. At some point, it would be nice to \n",
    "   Adjust this to handle unstructured data and alternative queries. \n",
    "\"\"\"\n",
    "def writeToCSV(data, location_info):\n",
    "    with open(OUT_FILE, \"a\") as file:\n",
    "        for metrics in data['metrics']:\n",
    "            for data in metrics['data']:\n",
    "                    line = location_info['store_id'] + \",\" \\\n",
    "                    + str(data['group']['finish']) +  \",\" \\\n",
    "                    + str(data['value'])+\"\\n\" \n",
    "                    file.write(line)\n",
    "                    \n",
    "\n",
    "def Final_inserting():\n",
    "    df_=pd.read_csv(OUT_FILE,header=None)\n",
    "    udaExec = teradata.UdaExec (appName=\"test\", version=\"1.0\", logConsole=False)\n",
    "    with udaExec.connect(method=\"odbc\",system=\"\", username=\"\",\n",
    "                      password=\"\", driver=\"Teradata Database ODBC Driver 16.20\") as connect:\n",
    "        data = [tuple(x) for x in df_.to_records(index=False)]\n",
    "        connect.executemany(\"INSERT INTO ABFRL_TSTAGE1_DEV.AEO_Traffic values(?,?,?)\",data,batch=True)\n",
    "    print(\"Records Inserted Succesfully\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "post_request = {\n",
    "   \"locations\" : [\n",
    "      \"<location-here>\"\n",
    "   ],\n",
    "   \"time_ranges\" : [\n",
    "      {\n",
    "         \"type\" : \"store_hours\"\n",
    "      }\n",
    "   ],\n",
    "   \"group_bys\" : [\n",
    "      {  \"value\": 1, \n",
    "         \"unit\": \"days\",\n",
    "         \"group\": \"date\"\n",
    "      } ,\n",
    "   ],\n",
    "   \"date_ranges\" : [\n",
    "      {\n",
    "         \"first_day\" : START_DATE,\n",
    "         \"last_day\" : STOP_DATE\n",
    "      }\n",
    "   ],\n",
    "   \"metrics\" : [\n",
    "      \"traffic_in\",\n",
    "   ]\n",
    "}\n",
    "\n",
    "def main():\n",
    "  get_locations()\n",
    "  Final_inserting()\n",
    "  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
